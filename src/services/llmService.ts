/**
 * 大语言模型服务模块
 * 提供与各类大语言模型交互的接口
 */

// 导入知识库服务
import { knowledgeBaseService } from './knowledgeBaseService';
import apiClient from '@/lib/apiClient';

// 模型类型定义
export interface LLMModel {
  id: string;
  name: string;
  description: string;
  strengths: string[];
  isDefault: boolean;
  apiKey?: string;
}

// 对话历史类型定义
export interface Message {
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp: number;
}

// 对话会话类型定义
export interface ConversationSession {
  id: string;
  name: string;
  modelId: string;
  messages: Message[];
  createdAt: number;
  updatedAt: number;
  isActive: boolean;
  tags?: string[];
  metadata?: Record<string, any>;
  // 主题追踪相关字段
  currentTopic?: string; // 当前对话主题
  topicHistory?: string[]; // 主题历史记录
  contextSummary?: string; // 对话上下文摘要，用于长对话
  lastMessageTimestamp?: number; // 最后消息时间戳
}

// 性能监控数据类型定义
export interface ModelPerformance {
  modelId: string;
  requestCount: number;
  successCount: number;
  failureCount: number;
  totalResponseTime: number;
  averageResponseTime: number;
  minResponseTime: number;
  maxResponseTime: number;
  lastRequestTime: number;
  lastSuccessTime: number;
  lastFailureTime: number;
}

// 性能监控记录类型定义
export interface PerformanceRecord {
  modelId: string;
  startTime: number;
  endTime: number;
  responseTime: number;
  success: boolean;
  error?: string;
  timestamp: number;
}

// 模型角色类型定义
export interface ModelRole {
  id: string;
  name: string;
  description: string;
  system_prompt: string;
  temperature: number;
  top_p: number;
  presence_penalty: number;
  frequency_penalty: number;
  is_default: boolean;
  created_at: number;
  updated_at: number;
  tags?: string[];
}

// 助手性格类型定义
export type AssistantPersonality = 
  | 'friendly'     // 友好
  | 'professional' // 专业
  | 'creative'     // 创意
  | 'humorous'     // 幽默
  | 'concise'      // 简洁
  // 新增更多性格选项
  | 'warm'         // 温暖
  | 'enthusiastic' // 热情
  | 'calm'         // 冷静
  | 'witty'        // 机智
  | 'scholarly'    // 博学
  | 'casual'       // 随意
  | 'strict'       // 严格
  | 'empathetic';  // 富有同理心

// 主题类型定义
export type AssistantTheme = 
  | 'light'     // 浅色主题
  | 'dark'      // 深色主题
  | 'auto'      // 自动主题（跟随系统）
  | 'custom';   // 自定义主题

// 缓存相关类型定义
export interface CacheItem {
  response: string;
  timestamp: number;
  conversationId?: string;
  topic?: string;
  // 缓存优先级：高优先级缓存更不容易被清除
  priority: 'high' | 'medium' | 'low';
}

// 自定义主题配置类型
export interface CustomThemeConfig {
  primaryColor: string;
  secondaryColor: string;
  backgroundColor: string;
  textColor: string;
  accentColor: string;
  borderColor: string;
  hoverColor: string;
  successColor: string;
  warningColor: string;
  errorColor: string;
  infoColor: string;
}

// 模型配置类型定义
export interface ModelConfig {
  temperature: number;
  top_p: number;
  max_tokens: number;
  timeout: number;
  system_prompt: string;
  max_history: number;
  stream: boolean;
  kimi_model: string;
  kimi_base_url: string;
  kimi_api_key?: string;
  retry: number;
  backoff_ms: number;
  deepseek_model?: string;
  deepseek_base_url?: string;
  deepseek_api_key?: string;
  // 新增通用高级参数
  presence_penalty: number;
  frequency_penalty: number;
  stop: string[];
  // 新增豆包模型配置
  doubao_model: string;
  doubao_base_url: string;
  // 新增文心一言模型配置
  wenxin_model: string;
  wenxin_base_url: string;
  // 新增通义千问模型配置
  qwen_model: string;
  qwen_base_url: string;
  qwen_api_key?: string;
  // 新增ChatGPT模型配置
  chatgpt_model: string;
  chatgpt_base_url: string;
  openai_api_key?: string;
  // 新增Gemini模型配置
  gemini_model: string;
  gemini_base_url: string;
  gemini_api_key?: string;
  // 新增Gork模型配置
  gork_model: string;
  gork_base_url: string;
  // 新增智谱模型配置
  zhipu_model: string;
  zhipu_base_url: string;
  zhipu_api_key?: string;
  // 新增对话相关配置
  enable_memory: boolean;
  memory_window: number;
  context_window: number;
  // 新增多模态配置
  enable_multimodal: boolean;
  image_resolution: string;
  // 新增安全配置
  enable_safety_check: boolean;
  safety_level: 'low' | 'medium' | 'high';
  // 新增角色配置
  current_role_id?: string;
  // 新增个性化设置
  personality: AssistantPersonality; // 助手性格
  theme: AssistantTheme; // 主题偏好
  customThemeConfig?: CustomThemeConfig; // 自定义主题配置
  show_preset_questions: boolean; // 是否显示预设问题
  enable_typing_effect: boolean; // 是否启用打字效果
  auto_scroll: boolean; // 是否自动滚动
  shortcut_key: string; // 快捷键
  enable_notifications: boolean; // 是否启用通知
}

// 通用图片生成参数类型
export type GenerateImageParams = {
  prompt: string
  size?: string
  n?: number
  seed?: number
  guidance_scale?: number
  response_format?: 'url' | 'b64_json'
  watermark?: boolean
  model?: string
  // 新增高级配置参数
  steps?: number
  style?: string
  negative_prompt?: string
  aspect_ratio?: string
  quality?: 'standard' | 'hd' | 'uhd'
  enable_style_optimization?: boolean
  reference_image?: string
  reference_strength?: number
  color_palette?: string[]
  composition_guidance?: string
  detail_level?: 'low' | 'medium' | 'high'
}

// 通用图片生成响应类型
export type GenerateImageResponse = {
  ok: boolean
  data?: any
  error?: string
}

// 可用的模型列表
export const AVAILABLE_MODELS: LLMModel[] = [
  {
    id: 'kimi',
    name: 'Kimi',
    description: 'Kimi（Moonshot AI），擅长中文长文创作与协作',
    strengths: ['中文对话', '长上下文写作', '检索增强'],
    isDefault: true
  },
  {
    id: 'deepseek',
    name: 'DeepSeek',
    description: '擅长传统纹样生成和文化元素融合',
    strengths: ['中文对话', '文化元素融合', '设计创意'],
    isDefault: false
  },
  {
    id: 'qwen',
    name: '通义千问',
    description: '阿里云DashScope，中文对话与综合任务表现优秀，支持图像生成',
    strengths: ['中文对话', '综合任务', '工具调用', '图像生成', '语音合成'],
    isDefault: false
  }
];

// 默认角色列表
export const DEFAULT_ROLES: ModelRole[] = [
  {
    id: 'default',
    name: '默认助手',
    description: '帮助创作者进行设计构思、文化融合和平台使用的全能助手',
    system_prompt: '你是一个专注于传统文化创作与设计的全能AI助手，服务于文创平台。请提供详细、具体、有用的回答，帮助用户解决在平台使用过程中遇到的各种问题，包括创作流程、AI生成功能、文化元素融合、作品上传、编辑、分享、推广、数据分析、账户设置等方面。你的回答应该友好、专业、易于理解，并且提供清晰的步骤和建议。同时，你需要具备丰富的传统文化知识，能够为用户提供关于传统纹样、非遗技艺、文化元素创新应用等方面的专业指导。',
    temperature: 0.7,
    top_p: 0.9,
    presence_penalty: 0,
    frequency_penalty: 0,
    is_default: true,
    created_at: Date.now(),
    updated_at: Date.now(),
    tags: ['默认', '创意', '帮助']
  },
  {
    id: 'designer',
    name: '设计专家',
    description: '专注于设计领域的专家，提供专业的设计建议和创意',
    system_prompt: '你是一位资深的设计专家，专注于视觉设计、UI/UX设计、创意设计、文化融合设计和传统元素创新应用。请提供专业、详细、实用的设计建议和创意构思，包括色彩搭配、排版设计、元素运用、风格定位等方面。你的回答应该具体、可操作，并且结合最新的设计趋势和传统美学。',
    temperature: 0.8,
    top_p: 0.95,
    presence_penalty: 0.1,
    frequency_penalty: 0.1,
    is_default: false,
    created_at: Date.now(),
    updated_at: Date.now(),
    tags: ['设计', '创意', '文化']
  },
  {
    id: 'coder',
    name: '代码助手',
    description: '帮助编写和优化代码的助手',
    system_prompt: '你是一位资深的软件开发工程师，擅长多种编程语言和技术栈。请提供准确、高效、安全的代码解决方案和优化建议。你的回答应该包括完整的代码示例、详细的解释和最佳实践。对于问题，要先理解需求，然后提供清晰、可运行的代码，并解释代码的工作原理和优化点。',
    temperature: 0.3,
    top_p: 0.8,
    presence_penalty: 0,
    frequency_penalty: 0,
    is_default: false,
    created_at: Date.now(),
    updated_at: Date.now(),
    tags: ['编程', '技术', '代码']
  },
  {
    id: 'writer',
    name: '文案专家',
    description: '专注于文案创作的专家，提供吸引人的文案建议',
    system_prompt: '你是一位资深的文案专家，擅长创作各种类型的文案，包括广告文案、营销文案、社交媒体文案、产品描述、品牌故事等。请提供吸引人、有创意、符合品牌调性的文案内容。你的回答应该结合目标受众、传播渠道和营销目标，提供具体、可直接使用的文案示例，并解释文案的创作思路和效果预期。',
    temperature: 0.9,
    top_p: 0.95,
    presence_penalty: 0.2,
    frequency_penalty: 0.1,
    is_default: false,
    created_at: Date.now(),
    updated_at: Date.now(),
    tags: ['文案', '创作', '营销']
  },
  {
    id: 'teacher',
    name: '教育导师',
    description: '提供详细解释和指导的教育导师',
    system_prompt: '你是一位耐心、详细的教育导师，擅长将复杂的概念简单化，帮助学习者理解各种知识。请提供清晰、详细、循序渐进的解释和指导。你的回答应该包括基本概念、核心原理、实际应用和练习建议，使用通俗易懂的语言和生动的例子，帮助学习者建立完整的知识体系。',
    temperature: 0.6,
    top_p: 0.85,
    presence_penalty: 0,
    frequency_penalty: 0,
    is_default: false,
    created_at: Date.now(),
    updated_at: Date.now(),
    tags: ['教育', '学习', '指导']
  }
];

// 默认模型配置
export const DEFAULT_CONFIG: ModelConfig = {
  temperature: 0.7,
  top_p: 0.9,
  max_tokens: 2000,
  timeout: 30000,
  system_prompt: '你是一个帮助创作者进行设计构思与文化融合的助手。',
  max_history: 10,
  stream: false,
  kimi_model: 'moonshot-v1-32k',
  kimi_base_url: 'https://api.moonshot.cn/v1',
  retry: 2,
  backoff_ms: 800,
  deepseek_model: 'deepseek-chat',
  deepseek_base_url: 'https://api.deepseek.com',
  // 新增通用高级参数默认值
  presence_penalty: 0,
  frequency_penalty: 0,
  stop: [],
  // 新增豆包模型配置默认值
  doubao_model: 'doubao-pro-32k',
  doubao_base_url: 'https://api.doubao.com/v1',
  // 新增文心一言模型配置默认值
  wenxin_model: 'ERNIE-Speed-8K',
  wenxin_base_url: 'https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/completions',
  // 新增通义千问模型配置默认值
  qwen_model: 'qwen-plus',
  qwen_base_url: 'https://dashscope.aliyuncs.com/api/v1',
  // 新增ChatGPT模型配置默认值
  chatgpt_model: 'gpt-4o',
  chatgpt_base_url: 'https://api.openai.com/v1',
  // 新增Gemini模型配置默认值
  gemini_model: 'gemini-1.5-flash',
  gemini_base_url: 'https://generativelanguage.googleapis.com/v1',
  // 新增Gork模型配置默认值
  gork_model: 'grok-beta',
  gork_base_url: 'https://api.x.ai/v1',
  // 新增智谱模型配置默认值
  zhipu_model: 'glm-4-plus',
  zhipu_base_url: 'https://open.bigmodel.cn/api/paas/v4',
  // 新增对话相关配置默认值
  enable_memory: true,
  memory_window: 20,
  context_window: 8192,
  // 新增多模态配置默认值
  enable_multimodal: true,
  image_resolution: '1024x1024',
  // 新增安全配置默认值
  enable_safety_check: true,
  safety_level: 'medium',
  // 新增角色配置默认值
  current_role_id: 'default',
  // 新增个性化设置默认值
  personality: 'friendly', // 默认友好性格
  theme: 'auto', // 默认自动主题
  customThemeConfig: { // 默认自定义主题配置
    primaryColor: '#6366f1',
    secondaryColor: '#8b5cf6',
    backgroundColor: '#ffffff',
    textColor: '#1f2937',
    accentColor: '#ec4899',
    borderColor: '#e5e7eb',
    hoverColor: '#f3f4f6',
    successColor: '#10b981',
    warningColor: '#f59e0b',
    errorColor: '#ef4444',
    infoColor: '#3b82f6'
  },
  show_preset_questions: true, // 默认显示预设问题
  enable_typing_effect: true, // 默认启用打字效果
  auto_scroll: true, // 默认自动滚动
  shortcut_key: 'ctrl+k', // 默认快捷键
  enable_notifications: false // 默认禁用通知
};

/**
   * 连接状态类型定义
   */
// 错误类型定义
export type ErrorType = 
  | 'NETWORK_ERROR' 
  | 'AUTH_ERROR' 
  | 'QUOTA_ERROR' 
  | 'RATE_LIMIT_ERROR' 
  | 'SERVER_ERROR' 
  | 'MODEL_ERROR' 
  | 'VALIDATION_ERROR' 
  | 'UNKNOWN_ERROR'
  // 新增更细粒度的错误类型
  | 'CONNECTION_TIMEOUT'      // 连接超时
  | 'API_KEY_INVALID'          // API密钥无效
  | 'API_KEY_MISSING'          // API密钥缺失
  | 'REQUEST_TOO_LARGE'        // 请求过大
  | 'RESPONSE_PARSE_ERROR'     // 响应解析错误
  | 'MODEL_UNAVAILABLE'        // 模型不可用
  | 'FEATURE_NOT_SUPPORTED'    // 功能不支持
  | 'CONTEXT_OVERFLOW'         // 上下文溢出
  | 'THROTTLING_ERROR'         // 节流错误
  | 'SERVICE_UNAVAILABLE';     // 服务不可用

// 错误详情类型定义
export interface ErrorDetail {
  type: ErrorType;
  message: string;
  originalError?: Error;
  modelId?: string;
  timestamp: number;
  retryable: boolean;
  // 新增字段
  errorCode?: string;          // 错误代码
  requestId?: string;          // 请求ID
  context?: Record<string, any>; // 错误上下文信息
  userFriendlyMessage?: string; // 对用户友好的错误提示
  suggestedActions?: string[];   // 建议的用户操作
}

// 连接状态类型定义
export type ConnectionStatus = 'connected' | 'connecting' | 'disconnected' | 'error';

// 意图类型定义
export type UserIntent = 
  | 'QUERY'          // 查询信息
  | 'GENERATE'       // 生成内容
  | 'EXPLAIN'        // 解释概念
  | 'HELP'           // 请求帮助
  | 'SETTING'        // 设置配置
  | 'FEEDBACK'       // 提供反馈
  | 'UNKNOWN';       // 未知意图

// 实体类型定义
export interface RecognizedEntity {
  type: string;       // 实体类型，如"PERSON"、"DATE"、"PLACE"等
  value: string;      // 实体值
  confidence: number; // 识别置信度
}

/**
   * LLM服务类
   */
class LLMService {
  private currentModel: LLMModel = AVAILABLE_MODELS.find(m => m.isDefault) || AVAILABLE_MODELS[0];
  private modelConfig: ModelConfig = { ...DEFAULT_CONFIG };
  // 对话会话相关属性
  private conversationSessions: ConversationSession[] = [];
  private currentSessionId: string = '';
  // 性能监控相关属性
  private performanceData: Record<string, ModelPerformance> = {};
  private performanceRecords: PerformanceRecord[] = [];
  private maxPerformanceRecords = 1000; // 最多保存1000条性能记录
  // 角色管理相关属性
  private roles: ModelRole[] = [...DEFAULT_ROLES];
  private currentRole: ModelRole = DEFAULT_ROLES.find(r => r.is_default) || DEFAULT_ROLES[0];
  // 连接状态相关属性
  private connectionStatus: Record<string, ConnectionStatus> = {};
  private connectionStatusListeners: Array<(modelId: string, status: ConnectionStatus, error?: string) => void> = [];

  // 分层缓存相关属性
  private responseCache: Map<string, CacheItem> = new Map();
  private cacheExpiryTime = 3600000; // 缓存过期时间：1小时
  private maxCacheSize = 100; // 最大缓存数量
  // 缓存统计
  private cacheStats = {
    hits: 0,
    misses: 0,
    evictions: 0,
    totalRequests: 0
  };
  // 错误处理相关属性
  private errorLogs: ErrorDetail[] = [];
  private maxErrorLogs = 500; // 最大错误日志数量
  private errorListeners: Array<(error: ErrorDetail) => void> = [];

  /**
   * 构造函数，初始化配置
   */
  constructor() {
    // 从localStorage加载保存的模型配置
    this.loadConfigFromStorage();
    // 从环境变量读取API密钥并更新模型配置
    this.loadApiKeysFromEnv();
    // 初始化会话系统
    this.initializeSessions();
    // 从localStorage加载保存的当前模型
    this.loadCurrentModelFromStorage();
  }
  
  /**
   * 从localStorage加载模型配置
   */
  private loadConfigFromStorage(): void {
    try {
      const savedConfig = localStorage.getItem('LLM_CONFIG');
      if (savedConfig) {
        const parsedConfig = JSON.parse(savedConfig);
        this.modelConfig = { ...this.modelConfig, ...parsedConfig };
      }
    } catch (error) {
      console.error('Failed to load config from localStorage:', error);
    }
  }
  
  /**
   * 从localStorage加载保存的当前模型
   */
  private loadCurrentModelFromStorage(): void {
    try {
      const savedModelId = localStorage.getItem('LLM_CURRENT_MODEL');
      if (savedModelId) {
        this.setCurrentModel(savedModelId, true);
      }
    } catch (error) {
      console.error('Failed to load current model from localStorage:', error);
    }
  }

  /**
   * 从环境变量加载API密钥
   */
  private loadApiKeysFromEnv(): void {
    // 获取环境变量
    const env = typeof import.meta !== 'undefined' && (import.meta as any).env || process.env || {};
    
    // 读取各个模型的API密钥
    const apiKeys = {
      kimi_api_key: env.VITE_KIMI_API_KEY || env.KIMI_API_KEY,
      deepseek_api_key: env.VITE_DEEPSEEK_API_KEY || env.DEEPSEEK_API_KEY,
      qwen_api_key: env.VITE_QWEN_API_KEY || env.QWEN_API_KEY,
      openai_api_key: env.VITE_OPENAI_API_KEY || env.OPENAI_API_KEY,
      gemini_api_key: env.VITE_GEMINI_API_KEY || env.GEMINI_API_KEY,
      zhipu_api_key: env.VITE_ZHIPU_API_KEY || env.ZHIPU_API_KEY,
    };
    
    // 更新模型配置
    this.modelConfig = {
      ...this.modelConfig,
      ...apiKeys
    };
  }

  /**
   * 设置当前使用的模型
   * @param modelId 模型ID
   * @param preserveHistory 是否保留对话历史
   */
  setCurrentModel(modelId: string, preserveHistory: boolean = false): void {
    const model = AVAILABLE_MODELS.find(m => m.id === modelId);
    if (model) {
      // 如果不保留历史，清除当前对话历史
      if (!preserveHistory) {
        this.clearHistory();
      }
      
      const previousModelId = this.currentModel.id;
      this.currentModel = model;
      
      try {
        localStorage.setItem('LLM_CURRENT_MODEL', model.id);
      } catch (error) {
        console.error('Failed to save current model to localStorage:', error);
      }
      
      // 触发模型切换事件
      this.emitModelChangeEvent(previousModelId, model.id);
    }
  }
  
  /**
   * 触发模型切换事件
   */
  private emitModelChangeEvent(previousModelId: string, newModelId: string): void {
    // 创建自定义事件
    const event = new CustomEvent('llm-model-changed', {
      detail: {
        previousModelId,
        newModelId,
        timestamp: Date.now()
      }
    });
    
    // 派发事件
    if (typeof window !== 'undefined') {
      window.dispatchEvent(event);
    }
  }

  /**
   * 获取当前使用的模型
   */
  getCurrentModel(): LLMModel {
    return this.currentModel;
  }

  /**
   * 更新模型配置
   */
  updateConfig(config: Partial<ModelConfig>): void {
    this.modelConfig = { ...this.modelConfig, ...config };
    try { localStorage.setItem('LLM_CONFIG', JSON.stringify(this.modelConfig)); } catch {}
  }

  /**
   * 获取当前模型配置
   */
  getConfig(): ModelConfig {
    return { ...this.modelConfig };
  }

  /**
   * 清除当前会话的对话历史
   */
  clearHistory(): void {
    const session = this.getCurrentSession();
    if (session) {
      session.messages = [];
      session.updatedAt = Date.now();
      this.saveSessions();
    }
  }
  
  /**
   * 初始化模型性能数据
   */
  private initializePerformanceData(modelId: string): void {
    if (!this.performanceData[modelId]) {
      this.performanceData[modelId] = {
        modelId,
        requestCount: 0,
        successCount: 0,
        failureCount: 0,
        totalResponseTime: 0,
        averageResponseTime: 0,
        minResponseTime: Infinity,
        maxResponseTime: 0,
        lastRequestTime: 0,
        lastSuccessTime: 0,
        lastFailureTime: 0
      };
    }
  }
  
  /**
   * 更新模型性能数据
   */
  private updatePerformanceData(record: PerformanceRecord): void {
    const { modelId, responseTime, success, error } = record;
    
    // 初始化性能数据（如果不存在）
    this.initializePerformanceData(modelId);
    
    const performance = this.performanceData[modelId];
    
    // 更新请求计数
    performance.requestCount++;
    performance.lastRequestTime = Date.now();
    
    if (success) {
      // 更新成功计数
      performance.successCount++;
      performance.lastSuccessTime = Date.now();
    } else {
      // 更新失败计数
      performance.failureCount++;
      performance.lastFailureTime = Date.now();
    }
    
    // 更新响应时间数据
    performance.totalResponseTime += responseTime;
    performance.averageResponseTime = performance.totalResponseTime / performance.requestCount;
    performance.minResponseTime = Math.min(performance.minResponseTime, responseTime);
    performance.maxResponseTime = Math.max(performance.maxResponseTime, responseTime);
    
    // 记录性能记录
    this.performanceRecords.push(record);
    
    // 限制性能记录数量
    if (this.performanceRecords.length > this.maxPerformanceRecords) {
      this.performanceRecords.shift();
    }
  }
  
  /**
   * 记录性能数据
   */
  private recordPerformance(modelId: string, startTime: number, success: boolean, error?: string): void {
    const endTime = Date.now();
    const responseTime = endTime - startTime;
    
    const record: PerformanceRecord = {
      modelId,
      startTime,
      endTime,
      responseTime,
      success,
      error,
      timestamp: endTime
    };
    
    this.updatePerformanceData(record);
  }
  
  /**
   * 获取模型性能数据
   */
  getPerformanceData(modelId?: string): ModelPerformance | Record<string, ModelPerformance> {
    if (modelId) {
      this.initializePerformanceData(modelId);
      return { ...this.performanceData[modelId] };
    }
    
    // 确保所有可用模型都有性能数据
    AVAILABLE_MODELS.forEach(model => {
      this.initializePerformanceData(model.id);
    });
    
    return { ...this.performanceData };
  }
  
  /**
   * 获取性能记录
   */
  getPerformanceRecords(modelId?: string, limit: number = 100): PerformanceRecord[] {
    let records = [...this.performanceRecords];
    
    if (modelId) {
      records = records.filter(record => record.modelId === modelId);
    }
    
    // 按时间倒序排列，返回最新的记录
    return records.sort((a, b) => b.timestamp - a.timestamp).slice(0, limit);
  }
  
  /**
   * 重置模型性能数据
   */
  resetPerformanceData(modelId?: string): void {
    if (modelId) {
      delete this.performanceData[modelId];
      this.performanceRecords = this.performanceRecords.filter(record => record.modelId !== modelId);
    } else {
      this.performanceData = {};
      this.performanceRecords = [];
    }
  }

  /**
   * 初始化角色系统
   */
  private initializeRoles(): void {
    try {
      const savedRoles = localStorage.getItem('LLM_ROLES');
      if (savedRoles) {
        const parsedRoles = JSON.parse(savedRoles);
        // 合并默认角色和保存的角色，避免丢失默认角色
        const roleMap = new Map<string, ModelRole>();
        
        // 先添加默认角色
        DEFAULT_ROLES.forEach(role => {
          roleMap.set(role.id, role);
        });
        
        // 再添加保存的角色，覆盖同名默认角色
        parsedRoles.forEach((role: ModelRole) => {
          roleMap.set(role.id, role);
        });
        
        this.roles = Array.from(roleMap.values());
      }
      
      const savedCurrentRoleId = localStorage.getItem('LLM_CURRENT_ROLE_ID');
      if (savedCurrentRoleId) {
        const role = this.roles.find(r => r.id === savedCurrentRoleId);
        if (role) {
          this.currentRole = role;
          this.applyRoleToConfig(role);
        }
      }
    } catch (error) {
      console.error('Failed to initialize roles:', error);
      // 初始化失败，使用默认角色
      this.roles = [...DEFAULT_ROLES];
      this.currentRole = DEFAULT_ROLES.find(r => r.is_default) || DEFAULT_ROLES[0];
      this.applyRoleToConfig(this.currentRole);
    }
  }

  /**
   * 识别用户查询意图
   * @param query 用户查询
   * @returns 识别的意图和置信度
   */
  private recognizeIntent(query: string): { intent: UserIntent; confidence: number } {
    const lowerQuery = query.toLowerCase();
    
    // 简单的意图识别逻辑，基于关键词匹配
    if (lowerQuery.includes('查询') || lowerQuery.includes('怎么') || lowerQuery.includes('如何') || lowerQuery.includes('什么')) {
      return { intent: 'QUERY', confidence: 0.9 };
    } else if (lowerQuery.includes('生成') || lowerQuery.includes('创建') || lowerQuery.includes('写') || lowerQuery.includes('设计')) {
      return { intent: 'GENERATE', confidence: 0.9 };
    } else if (lowerQuery.includes('解释') || lowerQuery.includes('说明') || lowerQuery.includes('什么是') || lowerQuery.includes('意思')) {
      return { intent: 'EXPLAIN', confidence: 0.9 };
    } else if (lowerQuery.includes('帮助') || lowerQuery.includes('使用') || lowerQuery.includes('教程')) {
      return { intent: 'HELP', confidence: 0.9 };
    } else if (lowerQuery.includes('设置') || lowerQuery.includes('配置') || lowerQuery.includes('调整')) {
      return { intent: 'SETTING', confidence: 0.9 };
    } else if (lowerQuery.includes('反馈') || lowerQuery.includes('建议') || lowerQuery.includes('评价')) {
      return { intent: 'FEEDBACK', confidence: 0.9 };
    }
    
    return { intent: 'UNKNOWN', confidence: 0.5 };
  }

  /**
   * 识别用户查询中的实体
   * @param query 用户查询
   * @returns 识别的实体列表
   */
  private recognizeEntities(query: string): RecognizedEntity[] {
    const entities: RecognizedEntity[] = [];
    
    // 简单的实体识别逻辑，基于正则表达式和关键词匹配
    
    // 1. 识别日期实体
    const dateRegex = /(\d{4}年\d{1,2}月\d{1,2}日|\d{4}-\d{1,2}-\d{1,2}|\d{1,2}\/\d{1,2}\/\d{4}|今天|明天|昨天|本周|下周|上个月|下个月)/g;
    let match;
    while ((match = dateRegex.exec(query)) !== null) {
      entities.push({
        type: 'DATE',
        value: match[0],
        confidence: 0.9
      });
    }
    
    // 2. 识别地点实体（简单示例，实际应用中需要更复杂的逻辑）
    const placeKeywords = ['北京', '上海', '广州', '深圳', '天津', '重庆', '成都', '杭州'];
    for (const keyword of placeKeywords) {
      if (query.includes(keyword)) {
        entities.push({
          type: 'PLACE',
          value: keyword,
          confidence: 0.8
        });
      }
    }
    
    // 3. 识别人物实体（简单示例）
    const personKeywords = ['李白', '杜甫', '苏轼', '白居易', '王维', '孟浩然'];
    for (const keyword of personKeywords) {
      if (query.includes(keyword)) {
        entities.push({
          type: 'PERSON',
          value: keyword,
          confidence: 0.8
        });
      }
    }
    
    // 4. 识别产品实体（简单示例）
    const productKeywords = ['AI助手', '创作工具', '文化知识', '文创产品', '社区活动'];
    for (const keyword of productKeywords) {
      if (query.includes(keyword)) {
        entities.push({
          type: 'PRODUCT',
          value: keyword,
          confidence: 0.8
        });
      }
    }
    
    return entities;
  }

  /**
   * 分析复杂查询结构
   * @param query 用户查询
   * @returns 分析结果，包括意图、实体和查询结构
   */
  private analyzeComplexQuery(query: string): {
    intent: UserIntent;
    entities: RecognizedEntity[];
    queryType: 'simple' | 'complex';
    subQueries?: string[];
  } {
    const intentResult = this.recognizeIntent(query);
    const entities = this.recognizeEntities(query);
    
    // 简单的查询结构分析，基于标点符号和连接词
    const hasMultipleQuestions = query.includes('?') && query.indexOf('?') !== query.lastIndexOf('?');
    const hasConjunctions = query.includes('和') || query.includes('并且') || query.includes('同时') || query.includes('还有');
    
    let queryType: 'simple' | 'complex' = 'simple';
    let subQueries: string[] | undefined;
    
    if (hasMultipleQuestions || hasConjunctions) {
      queryType = 'complex';
      
      // 简单的子查询分割，实际应用中需要更复杂的逻辑
      if (hasMultipleQuestions) {
        subQueries = query.split('?').filter(part => part.trim().length > 0).map(part => part.trim() + '?');
      } else if (hasConjunctions) {
        subQueries = query.split(/[和并且同时还有]/).filter(part => part.trim().length > 0).map(part => part.trim());
      }
    }
    
    return {
      intent: intentResult.intent,
      entities,
      queryType,
      subQueries
    };
  }

  /**
   * 生成动态提示词
   * 根据用户角色、当前页面和对话历史调整系统提示词
   */
  private generateDynamicPrompt(
    basePrompt: string,
    context?: {
      page?: string;
      path?: string;
      userPreferences?: Record<string, any>;
    }
  ): string {
    const session = this.getCurrentSession();
    const dynamicElements: string[] = [];
    
    // 1. 添加当前页面上下文
    if (context?.page) {
      dynamicElements.push(`\n\n当前用户正在访问页面：${context.page}`);
    }
    if (context?.path) {
      dynamicElements.push(`路径：${context.path}`);
    }
    
    // 2. 添加对话主题信息
    if (session?.currentTopic) {
      dynamicElements.push(`\n\n当前对话主题：${session.currentTopic}`);
      if (session.topicHistory && session.topicHistory.length > 0) {
        dynamicElements.push(`\n历史主题：${session.topicHistory.join(', ')}`);
      }
    }
    
    // 3. 添加个性化设置
    const personality = this.modelConfig.personality;
    switch (personality) {
      case 'friendly':
        dynamicElements.push(`\n\n请以友好、热情的语气回答用户的问题。`);
        break;
      case 'professional':
        dynamicElements.push(`\n\n请以专业、严谨的语气回答用户的问题，提供详细的技术解释。`);
        break;
      case 'creative':
        dynamicElements.push(`\n\n请以富有创意、想象力的语气回答用户的问题，提供创新的解决方案。`);
        break;
      case 'humorous':
        dynamicElements.push(`\n\n请以幽默、轻松的语气回答用户的问题，适当加入玩笑和有趣的比喻。`);
        break;
      case 'concise':
        dynamicElements.push(`\n\n请以简洁、明了的语气回答用户的问题，避免冗长的解释。`);
        break;
      // 新增性格选项的语气指导
      case 'warm':
        dynamicElements.push(`\n\n请以温暖、亲切的语气回答用户的问题，让用户感到舒适和被关心。`);
        break;
      case 'enthusiastic':
        dynamicElements.push(`\n\n请以充满热情和活力的语气回答用户的问题，展现积极向上的态度。`);
        break;
      case 'calm':
        dynamicElements.push(`\n\n请以冷静、沉稳的语气回答用户的问题，提供理性和客观的分析。`);
        break;
      case 'witty':
        dynamicElements.push(`\n\n请以机智、风趣的语气回答用户的问题，展现敏捷的思维和幽默。`);
        break;
      case 'scholarly':
        dynamicElements.push(`\n\n请以博学、严谨的语气回答用户的问题，提供深入的分析和专业知识。`);
        break;
      case 'casual':
        dynamicElements.push(`\n\n请以随意、轻松的语气回答用户的问题，就像和朋友聊天一样。`);
        break;
      case 'strict':
        dynamicElements.push(`\n\n请以严格、认真的语气回答用户的问题，强调准确性和规范性。`);
        break;
      case 'empathetic':
        dynamicElements.push(`\n\n请以富有同理心和理解力的语气回答用户的问题，表现出对用户感受的理解和支持。`);
        break;
      default:
        break;
    }
    
    // 4. 添加对话历史摘要（如果有）
    if (session?.contextSummary) {
      dynamicElements.push(`\n\n对话历史摘要：${session.contextSummary}`);
    }
    
    // 5. 添加模型特定指令
    const modelId = this.currentModel.id;
    switch (modelId) {
      case 'kimi':
        dynamicElements.push(`\n\n请充分利用Kimi的长上下文能力，提供详细、全面的回答。`);
        break;
      case 'deepseek':
        dynamicElements.push(`\n\n请结合Deepseek在文化元素融合方面的优势，提供富有文化内涵的回答。`);
        break;
      case 'qwen':
        dynamicElements.push(`\n\n请利用通义千问的综合能力，提供全面、准确的回答。`);
        break;
      default:
        break;
    }
    
    // 组合基础提示词和动态元素
    return `${basePrompt}${dynamicElements.join('')}`;
  }

  /**
   * 更新对话上下文摘要
   * 定期生成对话摘要，用于长对话管理
   */
  private updateContextSummary(): void {
    const session = this.getCurrentSession();
    if (!session || session.messages.length < 10) {
      // 对话历史较短，不需要生成摘要
      return;
    }
    
    // 简单的摘要生成逻辑：提取最近几条消息的关键词
    const recentMessages = session.messages.slice(-5);
    const combinedText = recentMessages.map(msg => msg.content).join(' ');
    
    // 这里可以替换为更复杂的摘要生成算法，甚至调用LLM生成摘要
    // 暂时使用简单的关键词提取
    const words = combinedText.toLowerCase().split(/\s+/);
    const stopWords = new Set(['的', '了', '是', '在', '我', '有', '和', '就', '不', '人', '都', '一', '一个', '上', '也', '很', '到', '说', '要', '去', '你', '会', '着', '没有', '看', '好', '自己', '这']);
    
    const filteredWords = words.filter(word => !stopWords.has(word) && word.length > 1);
    const wordFreq: Record<string, number> = {};
    filteredWords.forEach(word => {
      wordFreq[word] = (wordFreq[word] || 0) + 1;
    });
    
    const topWords = Object.entries(wordFreq)
      .sort((a, b) => b[1] - a[1])
      .slice(0, 10)
      .map(entry => entry[0]);
    
    session.contextSummary = `对话围绕以下主题展开：${topWords.join(', ')}`;
    this.saveSessions();
  }

  /**
   * 将角色配置应用到模型配置
   */
  private applyRoleToConfig(role: ModelRole): void {
    this.modelConfig = {
      ...this.modelConfig,
      system_prompt: role.system_prompt,
      temperature: role.temperature,
      top_p: role.top_p,
      presence_penalty: role.presence_penalty,
      frequency_penalty: role.frequency_penalty,
      current_role_id: role.id
    };
    
    // 保存更新后的配置
    try {
      localStorage.setItem('LLM_CONFIG', JSON.stringify(this.modelConfig));
    } catch (error) {
      console.error('Failed to save config with role:', error);
    }
  }
  
  /**
   * 保存角色到localStorage
   */
  private saveRoles(): void {
    try {
      localStorage.setItem('LLM_ROLES', JSON.stringify(this.roles));
      localStorage.setItem('LLM_CURRENT_ROLE_ID', this.currentRole.id);
    } catch (error) {
      console.error('Failed to save roles:', error);
    }
  }
  
  /**
   * 初始化会话系统
   */
  private initializeSessions(): void {
    // 先初始化角色系统
    this.initializeRoles();
    
    try {
      const savedSessions = localStorage.getItem('LLM_CONVERSATION_SESSIONS');
      if (savedSessions) {
        this.conversationSessions = JSON.parse(savedSessions);
      }
      
      const savedCurrentSessionId = localStorage.getItem('LLM_CURRENT_SESSION_ID');
      if (savedCurrentSessionId) {
        this.currentSessionId = savedCurrentSessionId;
      }
      
      // 如果没有会话或当前会话不存在，创建一个新会话
      if (this.conversationSessions.length === 0 || !this.getCurrentSession()) {
        this.createSession('新对话');
      }
    } catch (error) {
      console.error('Failed to initialize sessions:', error);
      // 初始化失败，创建一个默认会话
      this.createSession('新对话');
    }
  }
  
  /**
   * 保存会话到localStorage
   */
  private saveSessions(): void {
    try {
      localStorage.setItem('LLM_CONVERSATION_SESSIONS', JSON.stringify(this.conversationSessions));
      localStorage.setItem('LLM_CURRENT_SESSION_ID', this.currentSessionId);
    } catch (error) {
      console.error('Failed to save sessions:', error);
    }
  }
  
  /**
   * 创建新会话
   */
  createSession(name: string, modelId?: string): ConversationSession {
    const session: ConversationSession = {
      id: `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      name,
      modelId: modelId || this.currentModel.id,
      messages: [],
      createdAt: Date.now(),
      updatedAt: Date.now(),
      isActive: true,
      // 初始化主题追踪相关字段
      currentTopic: '',
      topicHistory: [],
      contextSummary: '',
      lastMessageTimestamp: Date.now()
    };
    
    // 停用当前会话
    const currentSession = this.getCurrentSession();
    if (currentSession) {
      currentSession.isActive = false;
    }
    
    // 添加新会话
    this.conversationSessions.push(session);
    this.currentSessionId = session.id;
    
    // 保存会话
    this.saveSessions();
    
    return session;
  }
  
  /**
   * 切换会话
   */
  switchSession(sessionId: string): void {
    const session = this.conversationSessions.find(s => s.id === sessionId);
    if (session) {
      // 停用当前会话
      const currentSession = this.getCurrentSession();
      if (currentSession) {
        currentSession.isActive = false;
      }
      
      // 激活新会话
      session.isActive = true;
      this.currentSessionId = session.id;
      
      // 切换到会话使用的模型
      this.setCurrentModel(session.modelId, true);
      
      // 保存会话
      this.saveSessions();
    }
  }
  
  /**
   * 删除会话
   */
  deleteSession(sessionId: string): void {
    const index = this.conversationSessions.findIndex(s => s.id === sessionId);
    if (index !== -1) {
      // 如果删除的是当前会话，切换到另一个会话
      if (sessionId === this.currentSessionId) {
        this.conversationSessions.splice(index, 1);
        
        if (this.conversationSessions.length > 0) {
          // 切换到第一个会话
          const newSession = this.conversationSessions[0];
          newSession.isActive = true;
          this.currentSessionId = newSession.id;
          this.setCurrentModel(newSession.modelId, true);
        } else {
          // 如果没有会话了，创建一个新会话
          this.createSession('新对话');
        }
      } else {
        // 删除非当前会话
        this.conversationSessions.splice(index, 1);
      }
      
      // 保存会话
      this.saveSessions();
    }
  }
  
  /**
   * 重命名会话
   */
  renameSession(sessionId: string, name: string): void {
    const session = this.conversationSessions.find(s => s.id === sessionId);
    if (session) {
      session.name = name;
      session.updatedAt = Date.now();
      this.saveSessions();
    }
  }
  
  /**
   * 获取当前会话
   */
  private getCurrentSession(): ConversationSession | undefined {
    return this.conversationSessions.find(s => s.id === this.currentSessionId);
  }
  
  /**
   * 获取所有会话
   */
  getSessions(): ConversationSession[] {
    return [...this.conversationSessions].sort((a, b) => b.updatedAt - a.updatedAt);
  }
  
  /**
   * 获取指定会话
   */
  getSession(sessionId: string): ConversationSession | undefined {
    return this.conversationSessions.find(s => s.id === sessionId);
  }
  
  /**
   * 获取当前会话的对话历史
   */
  getHistory(): Message[] {
    const session = this.getCurrentSession();
    return session ? [...session.messages] : [];
  }
  
  /**
   * 获取指定会话的对话历史
   */
  getSessionHistory(sessionId: string): Message[] {
    const session = this.getSession(sessionId);
    return session ? [...session.messages] : [];
  }
  
  /**
   * 导入对话历史到当前会话
   */
  importHistory(messages: Message[]): void {
    const session = this.getCurrentSession();
    if (session) {
      const limit = this.modelConfig.max_history || 10;
      const trimmed = messages.slice(-limit);
      session.messages = [...trimmed];
      session.updatedAt = Date.now();
      this.saveSessions();
      
      try {
        localStorage.setItem('LLM_HISTORY_IMPORTED_AT', String(Date.now()));
      } catch (error) {
        console.error('Failed to save import timestamp:', error);
      }
    }
  }
  
  /**
   * 导出当前会话
   */
  exportSession(): ConversationSession {
    const session = this.getCurrentSession();
    if (!session) {
      throw new Error('No active session');
    }
    return JSON.parse(JSON.stringify(session));
  }
  
  /**
   * 导入会话
   */
  importSession(sessionData: ConversationSession): ConversationSession {
    // 创建新会话ID，避免冲突
    const newSession: ConversationSession = {
      ...sessionData,
      id: `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      isActive: false,
      createdAt: Date.now(),
      updatedAt: Date.now()
    };
    
    this.conversationSessions.push(newSession);
    this.saveSessions();
    
    return newSession;
  }
  
  /**
   * 获取所有角色
   */
  getRoles(): ModelRole[] {
    return [...this.roles];
  }
  
  /**
   * 获取当前角色
   */
  getCurrentRole(): ModelRole {
    return { ...this.currentRole };
  }
  
  /**
   * 设置当前角色
   * @param roleId 角色ID
   */
  setCurrentRole(roleId: string): void {
    const role = this.roles.find(r => r.id === roleId);
    if (role) {
      this.currentRole = role;
      this.applyRoleToConfig(role);
      this.saveRoles();
      
      // 触发角色切换事件
      this.emitRoleChangeEvent(roleId);
    }
  }
  
  /**
   * 获取指定模型的连接状态
   * @param modelId 模型ID
   */
  getConnectionStatus(modelId: string): ConnectionStatus {
    return this.connectionStatus[modelId] || 'disconnected';
  }
  
  /**
   * 设置模型的连接状态
   * @param modelId 模型ID
   * @param status 连接状态
   * @param error 错误信息（可选）
   */
  private setConnectionStatus(modelId: string, status: ConnectionStatus, error?: string): void {
    this.connectionStatus[modelId] = status;
    
    // 触发连接状态变化事件
    this.emitConnectionStatusChange(modelId, status, error);
  }
  
  /**
   * 触发连接状态变化事件
   * @param modelId 模型ID
   * @param status 连接状态
   * @param error 错误信息（可选）
   */
  private emitConnectionStatusChange(modelId: string, status: ConnectionStatus, error?: string): void {
    // 调用所有监听器
    this.connectionStatusListeners.forEach(listener => {
      listener(modelId, status, error);
    });
    
    // 派发自定义事件
    if (typeof window !== 'undefined') {
      window.dispatchEvent(new CustomEvent('llm-connection-status-changed', {
        detail: {
          modelId,
          status,
          error,
          timestamp: Date.now()
        }
      }));
    }
  }
  
  /**
   * 触发角色切换事件
   */
  private emitRoleChangeEvent(roleId: string): void {
    // 创建自定义事件
    const event = new CustomEvent('llm-role-changed', {
      detail: {
        roleId,
        timestamp: Date.now()
      }
    });
    
    // 派发事件
    if (typeof window !== 'undefined') {
      window.dispatchEvent(event);
    }
  }
  
  /**
   * 创建新角色
   * @param roleData 角色数据
   */
  createRole(roleData: Omit<ModelRole, 'id' | 'created_at' | 'updated_at'>): ModelRole {
    const newRole: ModelRole = {
      ...roleData,
      id: `role_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      created_at: Date.now(),
      updated_at: Date.now()
    };
    
    this.roles.push(newRole);
    this.saveRoles();
    
    return newRole;
  }
  
  /**
   * 更新角色
   * @param roleId 角色ID
   * @param roleData 角色数据
   */
  updateRole(roleId: string, roleData: Partial<ModelRole>): ModelRole | null {
    const index = this.roles.findIndex(r => r.id === roleId);
    if (index !== -1) {
      const updatedRole: ModelRole = {
        ...this.roles[index],
        ...roleData,
        updated_at: Date.now()
      };
      
      this.roles[index] = updatedRole;
      this.saveRoles();
      
      // 如果更新的是当前角色，应用新配置
      if (roleId === this.currentRole.id) {
        this.currentRole = updatedRole;
        this.applyRoleToConfig(updatedRole);
      }
      
      return updatedRole;
    }
    
    return null;
  }
  
  /**
   * 删除角色
   * @param roleId 角色ID
   */
  deleteRole(roleId: string): boolean {
    // 不能删除默认角色
    const role = this.roles.find(r => r.id === roleId);
    if (role && role.is_default) {
      return false;
    }
    
    const index = this.roles.findIndex(r => r.id === roleId);
    if (index !== -1) {
      this.roles.splice(index, 1);
      this.saveRoles();
      
      // 如果删除的是当前角色，切换到默认角色
      if (roleId === this.currentRole.id) {
        const defaultRole = this.roles.find(r => r.is_default) || this.roles[0];
        this.setCurrentRole(defaultRole.id);
      }
      
      return true;
    }
    
    return false;
  }
  
  /**
   * 生成缓存键
   * 支持多种缓存级别：全局、对话、模型
   */
  private generateCacheKey(prompt: string, modelId: string, context?: any, cacheLevel: 'global' | 'conversation' | 'model' = 'global'): string {
    const contextStr = JSON.stringify(context || {});
    const session = this.getCurrentSession();
    const conversationId = session?.id || 'global';
    
    // 根据缓存级别生成不同的缓存键
    switch (cacheLevel) {
      case 'global':
        return `${modelId}:${this.currentRole.id}:${prompt}:${contextStr}`;
      case 'conversation':
        return `${modelId}:${this.currentRole.id}:${conversationId}:${prompt}:${contextStr}`;
      case 'model':
        return `${modelId}:${prompt}:${contextStr}`;
      default:
        return `${modelId}:${this.currentRole.id}:${prompt}:${contextStr}`;
    }
  }
  
  /**
   * 检查缓存
   * 支持智能缓存匹配和统计
   */
  private checkCache(prompt: string, modelId: string, context?: any): string | null {
    this.cacheStats.totalRequests++;
    
    // 生成不同级别的缓存键
    const cacheKeys = [
      this.generateCacheKey(prompt, modelId, context, 'conversation'),
      this.generateCacheKey(prompt, modelId, context, 'global'),
      this.generateCacheKey(prompt, modelId, context, 'model')
    ];
    
    const now = Date.now();
    
    // 依次检查不同级别的缓存
    for (const cacheKey of cacheKeys) {
      const cachedItem = this.responseCache.get(cacheKey);
      
      if (cachedItem) {
        // 检查缓存是否过期
        if (now - cachedItem.timestamp < this.cacheExpiryTime) {
          this.cacheStats.hits++;
          return cachedItem.response;
        } else {
          // 缓存过期，移除
          this.responseCache.delete(cacheKey);
          this.cacheStats.evictions++;
        }
      }
    }
    
    this.cacheStats.misses++;
    return null;
  }
  
  /**
   * 计算缓存优先级
   * 根据对话上下文和内容自动确定缓存优先级
   */
  private calculateCachePriority(prompt: string, response: string): 'high' | 'medium' | 'low' {
    // 简单的优先级计算逻辑
    const session = this.getCurrentSession();
    
    // 1. 如果是系统级提示或重要指令，优先级高
    if (prompt.includes('系统') || prompt.includes('设置') || prompt.includes('配置')) {
      return 'high';
    }
    
    // 2. 如果是当前对话的主题相关内容，优先级中
    if (session?.currentTopic && prompt.includes(session.currentTopic)) {
      return 'medium';
    }
    
    // 3. 其他情况优先级低
    return 'low';
  }
  
  /**
   * 更新缓存
   * 实现分层缓存和智能缓存失效
   */
  private updateCache(prompt: string, modelId: string, response: string, context?: any): void {
    const cacheKey = this.generateCacheKey(prompt, modelId, context, 'conversation');
    const session = this.getCurrentSession();
    
    // 计算缓存优先级
    const priority = this.calculateCachePriority(prompt, response);
    
    // 检查缓存大小，超过限制则移除优先级低的缓存
    if (this.responseCache.size >= this.maxCacheSize) {
      // 按优先级和时间排序，移除最应该被清除的缓存
      const cacheEntries = Array.from(this.responseCache.entries());
      cacheEntries.sort((a, b) => {
        // 先按优先级排序
        const priorityOrder = { high: 3, medium: 2, low: 1 };
        const priorityDiff = priorityOrder[b[1].priority] - priorityOrder[a[1].priority];
        if (priorityDiff !== 0) {
          return priorityDiff;
        }
        // 优先级相同时，按时间排序，移除最旧的
        return a[1].timestamp - b[1].timestamp;
      });
      
      // 移除最末尾的缓存（优先级最低且最旧）
      const itemToRemove = cacheEntries[cacheEntries.length - 1];
      this.responseCache.delete(itemToRemove[0]);
      this.cacheStats.evictions++;
    }
    
    // 添加新缓存
    this.responseCache.set(cacheKey, {
      response,
      timestamp: Date.now(),
      conversationId: session?.id,
      topic: session?.currentTopic,
      priority
    });
  }
  
  /**
   * 生成图片
   * 根据当前模型动态路由图片生成请求
   */
  async generateImage(params: GenerateImageParams): Promise<GenerateImageResponse> {
    const modelId = this.currentModel.id;
    let endpoint = '/api/doubao/images/generate';
    
    // 根据当前模型动态选择API端点
    switch (modelId) {
      case 'qwen':
        endpoint = '/api/qwen/images/generate';
        break;
      case 'deepseek':
        endpoint = '/api/deepseek/images/generate';
        break;
      case 'kimi':
        endpoint = '/api/kimi/images/generate';
        break;
      default:
        endpoint = '/api/doubao/images/generate';
    }
    
    try {
      const resp = await apiClient.post<GenerateImageResponse, GenerateImageParams>(endpoint, params, { retries: 1, timeoutMs: 20000 });
      if (!resp.ok) return { ok: false, error: resp.error };
      return resp.data as GenerateImageResponse;
    } catch (error) {
      console.error('Image generation failed:', error);
      return { ok: false, error: error instanceof Error ? error.message : '图片生成失败' };
    }
  }

  /**
   * 清除缓存
   * 支持按多种条件清除
   */
  clearCache(options?: {
    modelId?: string;
    conversationId?: string;
    topic?: string;
    priority?: 'high' | 'medium' | 'low';
  }): void {
    if (!options) {
      // 清除所有缓存
      this.responseCache.clear();
      return;
    }
    
    // 按条件清除缓存
    for (const [key, value] of this.responseCache.entries()) {
      let shouldDelete = false;
      
      if (options.modelId && key.startsWith(`${options.modelId}:`)) {
        shouldDelete = true;
      }
      
      if (options.conversationId && value.conversationId === options.conversationId) {
        shouldDelete = true;
      }
      
      if (options.topic && value.topic === options.topic) {
        shouldDelete = true;
      }
      
      if (options.priority && value.priority === options.priority) {
        shouldDelete = true;
      }
      
      if (shouldDelete) {
        this.responseCache.delete(key);
        this.cacheStats.evictions++;
      }
    }
  }
  
  /**
   * 获取缓存统计信息
   */
  getCacheStats() {
    return { ...this.cacheStats };
  }
  
  /**
   * 重置缓存统计信息
   */
  resetCacheStats() {
    this.cacheStats = {
      hits: 0,
      misses: 0,
      evictions: 0,
      totalRequests: 0
    };
  }
  
  /**
   * 获取对用户友好的错误提示和建议操作
   */
  private getFriendlyErrorInfo(errorType: ErrorType, modelId: string): {
    userFriendlyMessage: string;
    suggestedActions: string[];
  } {
    const modelName = AVAILABLE_MODELS.find(m => m.id === modelId)?.name || modelId;
    
    switch (errorType) {
      case 'NETWORK_ERROR':
      case 'CONNECTION_TIMEOUT':
        return {
          userFriendlyMessage: `网络连接失败，请检查您的网络设置后重试。`,
          suggestedActions: [
            '检查网络连接',
            '刷新页面重试',
            '稍后再试'
          ]
        };
        
      case 'AUTH_ERROR':
      case 'API_KEY_INVALID':
        return {
          userFriendlyMessage: `${modelName} API密钥无效，请检查并更新API密钥。`,
          suggestedActions: [
            '检查API密钥是否正确',
            '更新API密钥',
            '联系管理员获取帮助'
          ]
        };
        
      case 'API_KEY_MISSING':
        return {
          userFriendlyMessage: `${modelName} API密钥缺失，请配置API密钥。`,
          suggestedActions: [
            '在设置中配置API密钥',
            '联系管理员获取API密钥'
          ]
        };
        
      case 'QUOTA_ERROR':
        return {
          userFriendlyMessage: `${modelName} 配额已用完，请稍后再试或联系管理员。`,
          suggestedActions: [
            '稍后再试',
            '联系管理员增加配额',
            '切换到其他可用模型'
          ]
        };
        
      case 'RATE_LIMIT_ERROR':
      case 'THROTTLING_ERROR':
        return {
          userFriendlyMessage: `请求频率过高，请稍等片刻后重试。`,
          suggestedActions: [
            '稍等片刻后重试',
            '减少请求频率',
            '稍后再试'
          ]
        };
        
      case 'SERVER_ERROR':
      case 'SERVICE_UNAVAILABLE':
        return {
          userFriendlyMessage: `${modelName} 服务暂时不可用，请稍后再试。`,
          suggestedActions: [
            '稍后再试',
            '刷新页面',
            '切换到其他可用模型'
          ]
        };
        
      case 'MODEL_ERROR':
      case 'MODEL_UNAVAILABLE':
        return {
          userFriendlyMessage: `${modelName} 模型暂时不可用，请尝试其他模型。`,
          suggestedActions: [
            '切换到其他可用模型',
            '稍后再试',
            '联系管理员获取帮助'
          ]
        };
        
      case 'VALIDATION_ERROR':
      case 'REQUEST_TOO_LARGE':
        return {
          userFriendlyMessage: `请求参数无效或过大，请检查输入内容后重试。`,
          suggestedActions: [
            '检查输入内容是否符合要求',
            '减少输入内容的长度',
            '重新尝试'
          ]
        };
        
      case 'RESPONSE_PARSE_ERROR':
        return {
          userFriendlyMessage: `系统处理响应时出现错误，请稍后再试。`,
          suggestedActions: [
            '稍后再试',
            '刷新页面',
            '联系管理员获取帮助'
          ]
        };
        
      case 'FEATURE_NOT_SUPPORTED':
        return {
          userFriendlyMessage: `当前模型不支持该功能，请尝试其他模型。`,
          suggestedActions: [
            '切换到其他可用模型',
            '联系管理员获取帮助'
          ]
        };
        
      case 'CONTEXT_OVERFLOW':
        return {
          userFriendlyMessage: `对话历史过长，请清空部分历史或开始新对话。`,
          suggestedActions: [
            '清空对话历史',
            '开始新对话',
            '减少单次输入内容'
          ]
        };
        
      default:
        return {
          userFriendlyMessage: `系统出现未知错误，请稍后再试。`,
          suggestedActions: [
            '稍后再试',
            '刷新页面',
            '联系管理员获取帮助'
          ]
        };
    }
  }

  /**
   * 优化对话历史，实现智能选择和截断
   * 根据当前提示和最大历史长度，智能选择最相关的对话历史
   */
  private optimizeConversationHistory(messages: Message[], currentPrompt: string, maxHistory: number): Message[] {
    // 如果历史消息数量小于等于最大历史长度，直接返回
    if (messages.length <= maxHistory) {
      return messages;
    }
    
    // 简单的优化逻辑：保留最近的maxHistory条消息
    // 实际应用中可以实现更复杂的逻辑，如基于相关性的选择
    return messages.slice(-maxHistory);
  }

  /**
   * 更新对话主题
   * 根据对话历史和当前提示，自动更新对话主题
   */
  private updateConversationTopic(messages: Message[], currentPrompt: string): string {
    // 简单的主题提取逻辑：使用当前提示的前几个关键词
    // 实际应用中可以实现更复杂的主题提取算法
    const words = currentPrompt.toLowerCase().split(/\s+/);
    const stopWords = new Set(['的', '了', '是', '在', '我', '有', '和', '就', '不', '人', '都', '一', '一个', '上', '也', '很', '到', '说', '要', '去', '你', '会', '着', '没有', '看', '好', '自己', '这']);
    
    const filteredWords = words.filter(word => !stopWords.has(word) && word.length > 1);
    return filteredWords.slice(0, 3).join(' ');
  }

  /**
   * 构建多模态内容
   * 处理包含图像的多模态请求
   */
  private buildMultimodalContent(prompt: string, images?: string[]): any {
    // 简单的多模态内容构建逻辑
    // 实际应用中需要根据具体模型的API要求进行调整
    if (!images || images.length === 0) {
      return { text: prompt };
    }
    
    return {
      text: prompt,
      images: images.map(url => ({ url }))
    };
  }

  /**
   * 生成创意方向
   */
  public generateCreativeDirections(prompt: string): string[] {
    // 这里可以实现更复杂的创意方向生成逻辑
    return [
      '基于传统文化元素的创新设计',
      '结合现代科技的创意表现',
      '跨文化融合的设计思路',
      '注重可持续发展的设计理念',
      '以用户为中心的交互设计'
    ];
  }

  /**
   * 推荐文化元素
   */
  public recommendCulturalElements(prompt: string): string[] {
    // 这里可以实现更复杂的文化元素推荐逻辑
    return [
      '传统纹样',
      '民族色彩',
      '非遗技艺',
      '古典诗词',
      '历史典故'
    ];
  }

  /**
   * 诊断创作问题
   */
  public diagnoseCreationIssues(prompt: string): string[] {
    // 这里可以实现更复杂的创作问题诊断逻辑
    return [
      '创意方向不明确',
      '文化元素融合不够自然',
      '视觉层次不清晰',
      '色彩搭配不协调',
      '缺乏创新亮点'
    ];
  }

  /**
   * 获取回退响应
   */
  private getFallbackResponse(modelId: string, errorMessage: string): string {
    return `当前模型 ${modelId} 暂时无法提供服务，请稍后再试。错误信息：${errorMessage}`;
  }

  /**
   * 确保可用模型
   */
  async ensureAvailableModel(preferred: string[] = []): Promise<string> {
    const apiBase = (typeof import.meta !== 'undefined' && (import.meta as any).env && (import.meta as any).env.VITE_API_BASE_URL) || '';
    const useProxy = !!apiBase;

    // 首先检查当前模型是否可用
    const currentModel = this.getCurrentModel();
    const hasValidKey = this.hasValidApiKey(currentModel.id, useProxy);
    if (hasValidKey) {
      return currentModel.id;
    }

    // 检查首选模型列表
    for (const modelId of preferred) {
      if (this.hasValidApiKey(modelId, useProxy)) {
        return modelId;
      }
    }

    // 检查所有可用模型
    const availableModels = AVAILABLE_MODELS.filter(model => {
      return this.hasValidApiKey(model.id, useProxy);
    });

    // 按优先级排序模型
    const sortedModels = [...availableModels].sort((a, b) => {
      // 优先选择默认模型
      if (a.isDefault) return -1;
      if (b.isDefault) return 1;
      // 然后按ID排序
      return a.id.localeCompare(b.id);
    });

    // 返回第一个可用模型
    if (sortedModels.length > 0) {
      return sortedModels[0].id;
    }

    // 如果没有可用模型，返回当前模型（会触发错误处理）
    return currentModel.id;
  }

  /**
   * 生成响应
   * @param prompt 用户输入的提示词
   * @param options 可选配置，包括流式响应回调等
   * @returns 生成的响应文本
   */
  async generateResponse(prompt: string, options?: {
    onDelta?: (chunk: string) => void;
    signal?: AbortSignal;
    context?: {[key: string]: any};
  }): Promise<string> {
    try {
      // 记录性能开始时间
      const startTime = Date.now();
      const modelId = this.getCurrentModel().id;
      
      // 检查缓存
      const cacheKey = this.generateCacheKey(prompt, modelId, {}, 'conversation');
      const cachedResponse = this.responseCache.get(cacheKey);
      if (cachedResponse) {
        this.cacheStats.hits++;
        this.cacheStats.totalRequests++;
        if (options?.onDelta) {
          options.onDelta(cachedResponse.response);
        }
        return cachedResponse.response;
      }
      
      this.cacheStats.misses++;
      this.cacheStats.totalRequests++;
      
      // 构建对话历史
      const session = this.getCurrentSession();
      const history = session?.messages || [];
      const maxHistory = this.modelConfig.max_history || 10;
      const optimizedHistory = this.optimizeConversationHistory(history, prompt, maxHistory);
      
      // 构建请求消息
      const systemMessage = {
        role: 'system',
        content: this.generateDynamicPrompt(this.modelConfig.system_prompt, options?.context),
        timestamp: Date.now()
      };
      
      const userMessage = {
        role: 'user',
        content: prompt,
        timestamp: Date.now()
      };
      
      const messages = [systemMessage, ...optimizedHistory, userMessage];
      
      // 获取API基础URL和密钥
      const apiBase = (typeof import.meta !== 'undefined' && (import.meta as any).env && (import.meta as any).env.VITE_API_BASE_URL) || '';
      const useProxy = !!apiBase;
      
      // 更新连接状态为connecting
      this.setConnectionStatus(modelId, 'connecting');
      
      // 调用真实的LLM API
      let fullResponse: string;
      
      // 确保messages数组中的对象符合Message接口要求
      const typedMessages: Message[] = messages.map(msg => ({
        role: msg.role as 'user' | 'assistant' | 'system',
        content: msg.content,
        timestamp: msg.timestamp
      }));
      
      if (useProxy) {
        // 使用代理服务
        fullResponse = await this.callApiViaProxy(modelId, typedMessages, options);
      } else {
        // 直接调用模型API
        fullResponse = await this.callModelApiDirectly(modelId, typedMessages, options);
      }
      
      // API调用成功，更新连接状态为connected
      this.setConnectionStatus(modelId, 'connected');
      
      // 更新缓存
      this.updateCache(prompt, modelId, fullResponse);
      
      // 更新对话历史
      if (session) {
        // 确保userMessage符合Message接口要求
        const typedUserMessage: Message = {
          role: userMessage.role as 'user' | 'assistant' | 'system',
          content: userMessage.content,
          timestamp: userMessage.timestamp
        };
        
        // 添加消息到对话历史
        session.messages.push(typedUserMessage, {
          role: 'assistant',
          content: fullResponse,
          timestamp: Date.now()
        });
        session.updatedAt = Date.now();
        session.lastMessageTimestamp = Date.now();
        this.saveSessions();
      }
      
      // 记录性能结束时间
      const endTime = Date.now();
      
      // 更新性能数据
      this.updatePerformanceData({
        modelId,
        startTime,
        endTime,
        responseTime: endTime - startTime,
        success: true,
        timestamp: Date.now()
      });
      
      return fullResponse;
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : '未知错误';
      console.error('生成响应失败:', errorMessage);
      
      // API调用失败，更新连接状态为error
      this.setConnectionStatus(this.getCurrentModel().id, 'error', errorMessage);
      
      // 记录性能数据（失败情况）
      this.updatePerformanceData({
        modelId: this.getCurrentModel().id,
        startTime: Date.now(),
        endTime: Date.now(),
        responseTime: 0,
        success: false,
        error: errorMessage,
        timestamp: Date.now()
      });
      
      return this.getFallbackResponse(this.getCurrentModel().id, errorMessage);
    }
  }
  
  /**
   * 通过代理服务调用API
   */
  private async callApiViaProxy(modelId: string, messages: Message[], options?: {
    onDelta?: (chunk: string) => void;
    signal?: AbortSignal;
  }): Promise<string> {
    const apiBase = (typeof import.meta !== 'undefined' && (import.meta as any).env && (import.meta as any).env.VITE_API_BASE_URL) || '';
    const apiKey = (typeof import.meta !== 'undefined' && (import.meta as any).env && (import.meta as any).env.VITE_API_KEY) || '';
    
    const response = await fetch(`${apiBase}/api/chat`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: modelId,
        messages: messages.map(msg => ({ role: msg.role, content: msg.content })),
        stream: !!options?.onDelta,
        temperature: this.modelConfig.temperature,
        top_p: this.modelConfig.top_p,
        max_tokens: this.modelConfig.max_tokens,
      }),
      signal: options?.signal,
    });
    
    if (!response.ok) {
      throw new Error(`API请求失败: ${response.status} ${response.statusText}`);
    }
    
    if (options?.onDelta) {
      // 处理流式响应
      return this.handleStreamingResponse(response, options.onDelta);
    } else {
      // 处理非流式响应
      const data = await response.json();
      return data.choices[0]?.message?.content || '未获取到响应';
    }
  }
  
  /**
   * 直接调用模型API
   */
  private async callModelApiDirectly(modelId: string, messages: Message[], options?: {
    onDelta?: (chunk: string) => void;
    signal?: AbortSignal;
  }): Promise<string> {
    // 根据不同模型构建请求
    switch (modelId) {
      case 'kimi':
        return this.callKimiApi(messages, options);
      case 'deepseek':
        return this.callDeepseekApi(messages, options);
      case 'qwen':
        return this.callQwenApi(messages, options);
      default:
        throw new Error(`不支持的模型类型: ${modelId}`);
    }
  }
  
  /**
   * 调用Kimi API
   */
  private async callKimiApi(messages: Message[], options?: {
    onDelta?: (chunk: string) => void;
    signal?: AbortSignal;
  }): Promise<string> {
    const apiKey = this.modelConfig.kimi_api_key;
    if (!apiKey) {
      throw new Error('Kimi API密钥未配置');
    }
    
    const response = await fetch(`${this.modelConfig.kimi_base_url}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: this.modelConfig.kimi_model,
        messages: messages.map(msg => ({ role: msg.role, content: msg.content })),
        stream: !!options?.onDelta,
        temperature: this.modelConfig.temperature,
        top_p: this.modelConfig.top_p,
        max_tokens: this.modelConfig.max_tokens,
      }),
      signal: options?.signal,
    });
    
    if (!response.ok) {
      throw new Error(`Kimi API请求失败: ${response.status} ${response.statusText}`);
    }
    
    if (options?.onDelta) {
      // 处理流式响应
      return this.handleStreamingResponse(response, options.onDelta);
    } else {
      // 处理非流式响应
      const data = await response.json();
      return data.choices[0]?.message?.content || '未获取到响应';
    }
  }
  
  /**
   * 调用Deepseek API
   */
  private async callDeepseekApi(messages: Message[], options?: {
    onDelta?: (chunk: string) => void;
    signal?: AbortSignal;
  }): Promise<string> {
    const apiKey = this.modelConfig.deepseek_api_key;
    if (!apiKey) {
      throw new Error('Deepseek API密钥未配置');
    }
    
    const response = await fetch(`${this.modelConfig.deepseek_base_url}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: this.modelConfig.deepseek_model,
        messages: messages.map(msg => ({ role: msg.role, content: msg.content })),
        stream: !!options?.onDelta,
        temperature: this.modelConfig.temperature,
        top_p: this.modelConfig.top_p,
        max_tokens: this.modelConfig.max_tokens,
      }),
      signal: options?.signal,
    });
    
    if (!response.ok) {
      throw new Error(`Deepseek API请求失败: ${response.status} ${response.statusText}`);
    }
    
    if (options?.onDelta) {
      // 处理流式响应
      return this.handleStreamingResponse(response, options.onDelta);
    } else {
      // 处理非流式响应
      const data = await response.json();
      return data.choices[0]?.message?.content || '未获取到响应';
    }
  }
  
  /**
   * 调用通义千问API
   */
  private async callQwenApi(messages: Message[], options?: {
    onDelta?: (chunk: string) => void;
    signal?: AbortSignal;
  }): Promise<string> {
    // 通过后端代理服务器调用通义千问API，避免CORS错误
    // 不再需要前端API密钥，由后端从环境变量获取
    
    // 对于流式响应，暂时不使用apiClient，因为它不支持流式处理
    if (options?.onDelta) {
      const response = await fetch(`http://localhost:3010/api/qwen/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: this.modelConfig.qwen_model,
          messages: messages.map(msg => ({ role: msg.role, content: msg.content })),
          stream: true,
          temperature: this.modelConfig.temperature,
          top_p: this.modelConfig.top_p,
          max_tokens: this.modelConfig.max_tokens,
        }),
        signal: options?.signal,
      });
      
      if (!response.ok) {
        const errorData = await response.json().catch(() => ({}));
        throw new Error(`通义千问API请求失败: ${response.status} ${response.statusText} - ${errorData.error || ''}`);
      }
      
      // 处理流式响应
      return this.handleStreamingResponse(response, options.onDelta);
    } else {
      // 非流式响应直接使用fetch，确保发送到正确的端口
      const response = await fetch(`http://localhost:3010/api/qwen/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: this.modelConfig.qwen_model,
          messages: messages.map(msg => ({ role: msg.role, content: msg.content })),
          stream: false,
          temperature: this.modelConfig.temperature,
          top_p: this.modelConfig.top_p,
          max_tokens: this.modelConfig.max_tokens,
        }),
      });
      
      if (!response.ok) {
        throw new Error(`通义千问API请求失败: ${response.statusText || '未知错误'}`);
      }
      
      // 处理非流式响应
      const data = await response.json();
      // 通义千问API返回格式不同，直接返回text字段
      return data.data?.output?.text || data.output?.text || '未获取到响应';
    }
  }
  
  /**
   * 处理流式响应
   */
  private async handleStreamingResponse(response: Response, onDelta: (chunk: string) => void): Promise<string> {
    const reader = response.body?.getReader();
    if (!reader) {
      throw new Error('无法获取响应流');
    }
    
    const decoder = new TextDecoder('utf-8');
    let fullResponse = '';
    
    try {
      while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        
        const chunk = decoder.decode(value, { stream: true });
        const lines = chunk.split('\n');
        
        for (const line of lines) {
          const trimmedLine = line.trim();
          if (trimmedLine === '') continue;
          if (trimmedLine.startsWith('data: ')) {
            const data = trimmedLine.slice(6);
            if (data === '[DONE]') continue;
            
            try {
              const jsonData = JSON.parse(data);
              const content = jsonData.choices[0]?.delta?.content || '';
              if (content) {
                fullResponse += content;
                onDelta(content);
              }
            } catch (error) {
              console.error('解析流式响应失败:', error);
            }
          }
        }
      }
    } finally {
      reader.releaseLock();
    }
    
    return fullResponse;
  }

  /**
   * 检查API密钥是否有效
   */
  private hasValidApiKey(modelId: string, useProxy: boolean): boolean {
    // 如果使用代理，不需要检查API密钥
    if (useProxy) {
      return true;
    }

    // 根据模型ID检查API密钥
    switch (modelId) {
      case 'kimi':
        return !!this.modelConfig.kimi_api_key;
      case 'deepseek':
        return !!this.modelConfig.deepseek_api_key;
      case 'qwen':
        return !!this.modelConfig.qwen_api_key;
      case 'chatgpt':
        return !!this.modelConfig.openai_api_key;
      case 'gemini':
        return !!this.modelConfig.gemini_api_key;
      case 'zhipu':
        return !!this.modelConfig.zhipu_api_key;
      default:
        return false;
    }
  }
}

// 导出LLM服务实例
export const llmService = new LLMService();